{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Повторение"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Задача 1. \n",
    "\n",
    "Напишите функцию scramble: функция принимает на вход две строчки и должна проверить, чтобы из букв первой строки можно было составить вторую строку. Например, если у нас s1 = 'javascript', а s2 = 'java', то функция должна вернуть True. То же самое касательно варианта s1 = 'абырвалг' и s2 = 'главрыба', то есть, 1) вторая строка не обязательно содержит все буквы из первой, но если во второй строке две буквы \"с\", а в первой только одна, то должно быть False 2) буквы могут быть в любом порядке. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def scramble(s1=str, s2=str):\n",
    "    s1_dict = {}\n",
    "\n",
    "    for c in s1:\n",
    "        if c in s1_dict:\n",
    "            s1_dict[c] += 1\n",
    "        else:\n",
    "            s1_dict[c] = 1\n",
    "\n",
    "    print(s1_dict)\n",
    "\n",
    "    for c in s2:\n",
    "        if c in s1_dict:\n",
    "            s1_dict[c] -= 1\n",
    "            if s1_dict[c] == -1:\n",
    "                return False\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "scramble('абырвалг', 'главрыба')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Задача 2. \n",
    "\n",
    "Правильные скобки. На вход подается строка, которая содержит только и исключительно скобки трех видов: круглые, квадратные и фигурные. Например, '{[([({})])]}'. Ваша задача - написать функцию, которая бы проверяла правильность последовательности скобок и возвращала True или False. Примеры правильных и неправильных строк:\n",
    "\n",
    "    '[(])' = False\n",
    "    ')[](' = False\n",
    "    '{[()]}' = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def brackets(inp=str):\n",
    "    if len(inp) % 2 > 0:\n",
    "        return False\n",
    "\n",
    "    par_dict = {'(': ')', '{': '}', '[': ']'}\n",
    "\n",
    "    stack = []\n",
    "    for char in inp:\n",
    "        if char in par_dict.keys():\n",
    "            stack.append(char)\n",
    "        else:\n",
    "            if not stack:\n",
    "                return False\n",
    "\n",
    "            open_brace = stack.pop()\n",
    "\n",
    "            if char != par_dict[open_brace]:\n",
    "                return False\n",
    "\n",
    "    return not stack\n",
    "\n",
    "\n",
    "brackets('{[]}[{()}]')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Задача 3.\n",
    "\n",
    "Напишите программу, которая считывает содержимое (любого) текстового файла, разбивает его содержимое на слова, приводит их к леммам и составляет частотный словарь. Постройте график для десяти самых частотных слов с помощью библиотеки matplotlib."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import spacy\n",
    "import string\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "nlp = spacy.load('ru_core_news_sm')\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc(\n",
    "    'axes',\n",
    "    labelweight='bold',\n",
    "    labelsize='large',\n",
    "    titleweight='bold',\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "\n",
    "def lemmas_frequencies(filepath):\n",
    "    file = open(filepath, 'r', encoding='utf')\n",
    "\n",
    "    counts = {}\n",
    "    raw_words = []\n",
    "    for line in file:\n",
    "        x = line.lower().split()\n",
    "        for token in x:\n",
    "            raw_words.append(token)\n",
    "\n",
    "    words = []\n",
    "    for word in raw_words:\n",
    "        word = word.translate(str.maketrans('', '', string.punctuation + string.whitespace))\n",
    "        if word.isalpha():\n",
    "            words.append(word)\n",
    "\n",
    "    p = ' '.join(words)\n",
    "    doc = nlp(p)\n",
    "    lemmas = [token.lemma_ for token in doc]\n",
    "    for lemma in lemmas:\n",
    "        if lemma in counts:\n",
    "            counts[lemma] += 1\n",
    "        else:\n",
    "            counts[lemma] = 1\n",
    "    newcounts = sorted(counts.items(), key=lambda y: y[1], reverse=True)\n",
    "\n",
    "    print(newcounts[0:9])\n",
    "\n",
    "    top = newcounts[0:9]\n",
    "    x = [x[0] for x in top]\n",
    "    y = [x[1] for x in top]\n",
    "\n",
    "    sns.barplot(x=x, y=y)\n",
    "\n",
    "\n",
    "lemmas_frequencies('/Users/angelashumilova/Downloads/test_hw_base_1')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Задача 4.\n",
    "\n",
    "Постройте деревья зависимостей (любым известным вам способом) для любых трех выбранных вами предложений. Парсер тоже можно использовать любой, какой помните."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('ru_core_news_sm')\n",
    "sentence = 'Постройте деревья зависимостей (любым известным вам способом) для любых трех выбранных вами предложений. Парсер тоже можно использовать любой, какой помните. А теперь очень похожий квест, но с глаголами'\n",
    "doc = nlp(sentence)\n",
    "print(f\"{'Node (from)-->':<15} {'Relation':^10} {'-->Node (to)':>15}\\n\")\n",
    "\n",
    "for token in doc:\n",
    "    print(\"{:<15} {:^10} {:>15}\".format(str(token.head.text), str(token.dep_), str(token.text)))\n",
    "\n",
    "displacy.render(doc, style='dep')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Задача 5. \n",
    "\n",
    "Возьмите любой текстовый файл и попробуйте поискать в нем редупликации вида \"X-то X\". Нас устроит все, похожее на \"дурак-то он дурак\", \"красивая-то красивая\": между словами с повтором может что-то быть, как в первом примере, а может ничего не быть. Подумайте сами, насколько далеко могут отстоять друг от друга повторяющиеся слова. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import regex as re\n",
    "\n",
    "text = 'красивая-то y f , d красивая дурак дурак'\n",
    "re.findall(r'((\\w+)-то(?:\\W*(?:\\w+)?\\W+?){0,4}\\2)', text)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "7baf1831-2f6b-4ec1-9a54-4da466132393",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Задача 6. \n",
    "\n",
    "А теперь очень похожий квест, но с глаголами: ищем конструкции вида \"сделать я сделал\", \"пойти он пошел\". Очевидно, что здесь пригодится какая-нибудь лемматизация. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2bffb2-8985-4f48-9a63-065e3ab55a53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import regex as re\n",
    "\n",
    "nlp = spacy.load('ru_core_news_sm')\n",
    "\n",
    "def verbs_searcher (filepath):\n",
    "    file = open(filepath, 'r', encoding='utf')\n",
    "\n",
    "    raw_words = []\n",
    "    for line in file:\n",
    "        x = line.lower().split()\n",
    "        for token in x:\n",
    "            raw_words.append(token)\n",
    "\n",
    "    words = []\n",
    "    for word in raw_words:\n",
    "        word = word.translate(str.maketrans('', '', string.punctuation + string.whitespace))\n",
    "        if word.isalpha():\n",
    "            words.append(word)\n",
    "\n",
    "    p = ' '.join(words)\n",
    "    doc = nlp(p)\n",
    "    re.findall(r'((\\w+)(?:\\W*(?:\\w+)?\\W+?){1}\\2)', doc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}